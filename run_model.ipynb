{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir(\"birthrate_mtgp\")\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import numpyro.distributions as dist\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "from numpyro.handlers import scope\n",
    "\n",
    "from models.panel_nmf_model import model\n",
    "from models.utils import missingness_adjustment\n",
    "from numpyro_to_draws_df_csv import dict_to_tidybayes\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some defaults for testing\n",
    "dist = \"NB\"\n",
    "outcome_type = \"births\"\n",
    "cat_name = \"total\"\n",
    "rank = 5\n",
    "sample_disp = False\n",
    "missingness=True\n",
    "disp_param = 1e-4\n",
    "model_treated = True\n",
    "placebo_time = \"2019-03-01\"\n",
    "num_chains = 1\n",
    "num_samples = 100\n",
    "num_warmup=100\n",
    "start_time = '2016-01-01'\n",
    "end_time = '2024-01-01'\n",
    "def run_model(dist, outcome_type=\"births\", cat_name=\"total\", rank=5, missingness=True, \n",
    "         disp_param=1e-4, sample_disp=False, placebo_state = None, \n",
    "         start_time = '2016-01-01', end_time = '2023-12-31',\n",
    "         placebo_time = None, dobbs_donor_sensitivity=False,\n",
    "         model_treated=True, results_file_suffix = \"\",\n",
    "         num_chains=num_chains, num_warmup=1000, num_samples=1000, thinning=1):\n",
    "    \n",
    "    numpyro.set_host_device_count(num_chains)\n",
    "\n",
    "    # df = pd.read_csv('data/dobbsbimonthlybirths_10_23_24.csv')\n",
    "    df = pd.read_csv('/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_birth_update.csv')\n",
    "    \n",
    "    from clean_monthly_birth_data import prep_data, clean_dataframe, create_unit_placebo_dataset, create_time_placebo_dataset\n",
    "    \n",
    "    df = clean_dataframe(df, outcome_type, cat_name,  \n",
    "                         dobbs_donor_sensitivity=dobbs_donor_sensitivity, csv_filename=None)\n",
    "    df = df[df['time'] <= pd.to_datetime(end_time)]\n",
    "    df = df.sort_values(by=['state', 'year', 'bmcode']) \n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    if placebo_state is not None and placebo_state != \"Texas\":\n",
    "        df = create_unit_placebo_dataset(df, placebo_state = placebo_state)\n",
    "    \n",
    "    if placebo_time is not None:\n",
    "        df = create_time_placebo_dataset(df, new_treatment_start = placebo_time)\n",
    "    else:\n",
    "        # Only use data from 2016 onwards if not using a placebo time\n",
    "        df = df[df['time'] >= pd.to_datetime(start_time)]  \n",
    "\n",
    "    data_dict_cat = prep_data(df, outcome_type=outcome_type, group=cat_name)\n",
    "\n",
    "    data_dict_cat['Y'].shape\n",
    "    data_dict_cat['denominators'].shape\n",
    "    data_dict_cat['control_idx_array'].shape\n",
    "    \n",
    "    import numpy as np\n",
    "    from jax import random\n",
    "    from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "    #from models.monthly_model import monthly_model\n",
    "\n",
    "    # set the random seed\n",
    "    rng_key = random.PRNGKey(8675309)\n",
    "    # split the random key\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    # Setup the sampler\n",
    "    kernel = NUTS(model)\n",
    "\n",
    "    mcmc = MCMC(\n",
    "        kernel,\n",
    "        num_warmup=num_warmup,\n",
    "        num_samples=num_samples,\n",
    "        num_chains=num_chains,\n",
    "        progress_bar=True,\n",
    "        thinning=thinning\n",
    "    )\n",
    "\n",
    "    mcmc.run(\n",
    "        rng_key_,\n",
    "        y=data_dict_cat['Y'],\n",
    "        denominators=data_dict_cat['denominators'],\n",
    "        control_idx_array=data_dict_cat['control_idx_array'],\n",
    "        missing_idx_array=data_dict_cat['missing_idx_array'],\n",
    "        rank=rank,\n",
    "        outcome_dist=dist,\n",
    "        adjust_for_missingness=missingness,\n",
    "        nb_disp = disp_param,\n",
    "        sample_disp = sample_disp,\n",
    "        model_treated = model_treated\n",
    "    )\n",
    "\n",
    "    samples = mcmc.get_samples(group_by_chain=True)\n",
    "    predictive = Predictive(model, mcmc.get_samples(group_by_chain=False))\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "    predictions = predictive(\n",
    "        rng_key_,\n",
    "        denominators=data_dict_cat['denominators'],\n",
    "        control_idx_array=None, #data_dict_cat['control_idx_array'],\n",
    "        missing_idx_array=None, #data_dict_cat['missing_idx_array'],\n",
    "        rank=rank,\n",
    "        outcome_dist=dist,\n",
    "        nb_disp = disp_param,\n",
    "        sample_disp = sample_disp,\n",
    "        model_treated = False\n",
    "    )['y_obs']\n",
    "    K, D, N = data_dict_cat['denominators'].shape\n",
    "    pred_mat = predictions.reshape(mcmc.num_chains, int(mcmc.num_samples / mcmc.thinning), K, D, N)\n",
    "   \n",
    "    ## Take Python output and convert to draws matrix form\n",
    "    params = dict_to_tidybayes({'mu': samples['mu_ctrl'], 'te': samples['te'], 'disp' : samples['disp']})\n",
    "    preds = dict_to_tidybayes({\"ypred\" : pred_mat})\n",
    "\n",
    "    preds[\".chain\"] = params[\".chain\"]\n",
    "    preds[\".draw\"] = params[\".draw\"]\n",
    "\n",
    "    all_samples = params.merge(preds, left_on = ['.draw', '.chain'], right_on = ['.draw', '.chain'])\n",
    "    results_df = pd.DataFrame(all_samples)\n",
    "\n",
    "    ## save input df\n",
    "    df.to_csv('/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/df_{}.csv'.format(results_file_suffix))\n",
    "    ## save posterior samples\n",
    "    results_df.to_csv(\n",
    "        '/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/{}_{}_{}_{}_{}.csv'.format(dist, \"births\", cat_name, rank, results_file_suffix)\n",
    "    )\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    from clean_monthly_birth_data import subgroup_definitions\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    # Define the inputs for the function\n",
    "    inputs = [6, 7, 8, 9, 10, 11, 12]\n",
    "    outcome_type = \"births\" \n",
    "    cats = list(subgroup_definitions[outcome_type].keys())\n",
    "    dists = ['NB'] # Poisson or NB\n",
    "    missing_flags = [True]\n",
    "    # disp_params = [1e-4, 1e-3]\n",
    "    disp_params = [1e-4]\n",
    "    ## placebo_times = [\"2020-05-01\"]\n",
    "    placebo_times = [None]\n",
    "    placebo_states = [None]\n",
    "    sample_disp = False\n",
    "    dobbs_donor_sensitivity = False\n",
    "\n",
    "    args = [(dist, cat, rank, m, disp, p, tm) for dist in dists for rank in inputs for cat in cats \n",
    "            for m in missing_flags for disp in disp_params for p in placebo_states \n",
    "            for tm in placebo_times]\n",
    "    # Run the function in parallel\n",
    "    results = Parallel(n_jobs=100)(delayed(run_model)(dist=i[0], outcome_type=outcome_type, cat_name=i[1], rank=i[2], missingness=i[3], \n",
    "                                                disp_param=i[4],\n",
    "                                                sample_disp=sample_disp, placebo_state=i[5], placebo_time = i[6], \n",
    "                                                dobbs_donor_sensitivity=dobbs_donor_sensitivity, \n",
    "                                                results_file_suffix=\"through_june\", num_chains=4, num_samples=2500, num_warmup=1000, thinning=10) for i in args)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some defaults for testing\n",
    "dist = \"NB\"\n",
    "outcome_type = \"births\"\n",
    "cat_name = \"total\"\n",
    "rank = 5\n",
    "sample_disp = False\n",
    "missingness=True\n",
    "disp_param = 1e-4\n",
    "model_treated = True\n",
    "placebo_time = \"2019-03-01\"\n",
    "num_chains = 1\n",
    "num_samples = 100\n",
    "num_warmup=100\n",
    "start_time = '2016-01-01'\n",
    "end_time = '2024-01-01'\n",
    "def run_model(dist, outcome_type=\"births\", cat_name=\"total\", rank=5, missingness=True, \n",
    "         disp_param=1e-4, sample_disp=False, placebo_state = None, \n",
    "         start_time = '2016-01-01', end_time = '2023-12-31',\n",
    "         placebo_time = None, dobbs_donor_sensitivity=False,\n",
    "         model_treated=True, results_file_suffix = \"\",\n",
    "         num_chains=num_chains, num_warmup=1000, num_samples=1000, thinning=1):\n",
    "    \n",
    "    numpyro.set_host_device_count(num_chains)\n",
    "\n",
    "    # df = pd.read_csv('data/dobbsbimonthlybirths_10_23_24.csv')\n",
    "    df = pd.read_csv('/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_birth_update.csv')\n",
    "    \n",
    "    from clean_monthly_birth_data import prep_data, clean_dataframe, create_unit_placebo_dataset, create_time_placebo_dataset\n",
    "    \n",
    "    df = clean_dataframe(df, outcome_type, cat_name,  \n",
    "                         dobbs_donor_sensitivity=dobbs_donor_sensitivity, csv_filename=None)\n",
    "    df = df[df['time'] <= pd.to_datetime(end_time)]\n",
    "    df = df.sort_values(by=['state', 'year', 'bmcode']) \n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    if placebo_state is not None and placebo_state != \"Texas\":\n",
    "        df = create_unit_placebo_dataset(df, placebo_state = placebo_state)\n",
    "    \n",
    "    if placebo_time is not None:\n",
    "        df = create_time_placebo_dataset(df, new_treatment_start = placebo_time)\n",
    "    else:\n",
    "        # Only use data from 2016 onwards if not using a placebo time\n",
    "        df = df[df['time'] >= pd.to_datetime(start_time)]  \n",
    "\n",
    "    data_dict_cat = prep_data(df, outcome_type=outcome_type, group=cat_name)\n",
    "\n",
    "    data_dict_cat['Y'].shape\n",
    "    data_dict_cat['denominators'].shape\n",
    "    data_dict_cat['control_idx_array'].shape\n",
    "    \n",
    "    import numpy as np\n",
    "    from jax import random\n",
    "    from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "    #from models.monthly_model import monthly_model\n",
    "\n",
    "    # set the random seed\n",
    "    rng_key = random.PRNGKey(8675309)\n",
    "    # split the random key\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    # Setup the sampler\n",
    "    kernel = NUTS(model)\n",
    "\n",
    "    mcmc = MCMC(\n",
    "        kernel,\n",
    "        num_warmup=num_warmup,\n",
    "        num_samples=num_samples,\n",
    "        num_chains=num_chains,\n",
    "        progress_bar=True,\n",
    "        thinning=thinning\n",
    "    )\n",
    "\n",
    "    mcmc.run(\n",
    "        rng_key_,\n",
    "        y=data_dict_cat['Y'],\n",
    "        denominators=data_dict_cat['denominators'],\n",
    "        control_idx_array=data_dict_cat['control_idx_array'],\n",
    "        missing_idx_array=data_dict_cat['missing_idx_array'],\n",
    "        rank=rank,\n",
    "        outcome_dist=dist,\n",
    "        adjust_for_missingness=missingness,\n",
    "        nb_disp = disp_param,\n",
    "        sample_disp = sample_disp,\n",
    "        model_treated = model_treated\n",
    "    )\n",
    "\n",
    "    samples = mcmc.get_samples(group_by_chain=True)\n",
    "    predictive = Predictive(model, mcmc.get_samples(group_by_chain=False))\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "    predictions = predictive(\n",
    "        rng_key_,\n",
    "        denominators=data_dict_cat['denominators'],\n",
    "        control_idx_array=None, #data_dict_cat['control_idx_array'],\n",
    "        missing_idx_array=None, #data_dict_cat['missing_idx_array'],\n",
    "        rank=rank,\n",
    "        outcome_dist=dist,\n",
    "        nb_disp = disp_param,\n",
    "        sample_disp = sample_disp,\n",
    "        model_treated = False\n",
    "    )['y_obs']\n",
    "    K, D, N = data_dict_cat['denominators'].shape\n",
    "    pred_mat = predictions.reshape(mcmc.num_chains, int(mcmc.num_samples / mcmc.thinning), K, D, N)\n",
    "   \n",
    "    ## Take Python output and convert to draws matrix form\n",
    "    params = dict_to_tidybayes({'mu': samples['mu_ctrl'], 'te': samples['te'], 'disp' : samples['disp']})\n",
    "    preds = dict_to_tidybayes({\"ypred\" : pred_mat})\n",
    "\n",
    "    preds[\".chain\"] = params[\".chain\"]\n",
    "    preds[\".draw\"] = params[\".draw\"]\n",
    "\n",
    "    all_samples = params.merge(preds, left_on = ['.draw', '.chain'], right_on = ['.draw', '.chain'])\n",
    "    results_df = pd.DataFrame(all_samples)\n",
    "\n",
    "    ## save input df\n",
    "    df.to_csv('/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/df_{}.csv'.format(results_file_suffix))\n",
    "    ## save posterior samples\n",
    "    results_df.to_csv(\n",
    "        '/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/{}_{}_{}_{}_{}.csv'.format(dist, \"births\", cat_name, rank, results_file_suffix)\n",
    "    )\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    from clean_monthly_birth_data import subgroup_definitions\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    # Define the inputs for the function\n",
    "    inputs = [6, 7, 8, 9, 10, 11, 12]\n",
    "    outcome_type = \"births\" \n",
    "    cats = list(subgroup_definitions[outcome_type].keys())\n",
    "    dists = ['NB'] # Poisson or NB\n",
    "    missing_flags = [True]\n",
    "    # disp_params = [1e-4, 1e-3]\n",
    "    disp_params = [1e-4]\n",
    "    ## placebo_times = [\"2020-05-01\"]\n",
    "    placebo_times = [None]\n",
    "    placebo_states = [None]\n",
    "    sample_disp = False\n",
    "    dobbs_donor_sensitivity = False\n",
    "\n",
    "    args = [(dist, cat, rank, m, disp, p, tm) for dist in dists for rank in inputs for cat in cats \n",
    "            for m in missing_flags for disp in disp_params for p in placebo_states \n",
    "            for tm in placebo_times]\n",
    "    # Run the function in parallel\n",
    "    results = Parallel(n_jobs=8)(delayed(run_model)(dist=i[0], outcome_type=outcome_type, cat_name=i[1], rank=i[2], missingness=i[3], \n",
    "                                                disp_param=i[4],\n",
    "                                                sample_disp=sample_disp, placebo_state=i[5], placebo_time = i[6], \n",
    "                                                dobbs_donor_sensitivity=dobbs_donor_sensitivity, \n",
    "                                                results_file_suffix=\"through_june\", num_samples=2500, num_warmup=1000, thinning=10) for i in args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPC Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing categories: ['race', 'edu', 'age', 'insurance', 'marital', 'total']\n",
      "\n",
      "Raw results:\n",
      "  category  rank    waic     loo\n",
      "0     race     6  1250.0  1260.0\n",
      "1     race     7  1250.0  1260.0\n",
      "2     race     8  1250.0  1260.0\n",
      "3     race     9  1250.0  1260.0\n",
      "4     race    10  1250.0  1260.0\n",
      "\n",
      "✅ Optimal ranks:\n",
      "age: rank 6\n",
      "edu: rank 6\n",
      "insurance: rank 6\n",
      "marital: rank 6\n",
      "race: rank 6\n",
      "total: rank 6\n",
      "\n",
      "Final result: {'age': 6, 'edu': 6, 'insurance': 6, 'marital': 6, 'race': 6, 'total': 6}\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_ranks(outcome_type=\"births\", rank_candidates=[6,7,8,9,10,11,12], n_jobs=4):\n",
    "    \"\"\"Find optimal ranks for all available categories\"\"\"\n",
    "    # 1. Get valid categories\n",
    "    try:\n",
    "        cats = list(subgroup_definitions[outcome_type].keys())\n",
    "        print(f\"Testing categories: {cats}\")\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Outcome type '{outcome_type}' not found in subgroup_definitions\")\n",
    "\n",
    "    # 2. Define the testing function\n",
    "    def test_rank(cat, rank):\n",
    "        try:\n",
    "            # [Previous model code...]\n",
    "            return {\n",
    "                'category': cat,  # Changed from 'cat' to be explicit\n",
    "                'rank': rank,\n",
    "                'waic': 1250.0,  # Example value - replace with real WAIC\n",
    "                'loo': 1260.0    # Example value\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {cat} (rank {rank}) failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # 3. Run tests\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(test_rank)(cat, rank)\n",
    "        for cat in cats\n",
    "        for rank in rank_candidates\n",
    "    )\n",
    "    \n",
    "    # 4. Process results\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    \n",
    "    if not valid_results:\n",
    "        raise ValueError(\"All model runs failed! Check your data and model setup.\")\n",
    "    \n",
    "    df_results = pd.DataFrame(valid_results)\n",
    "    \n",
    "    # Debug print\n",
    "    print(\"\\nRaw results:\")\n",
    "    print(df_results.head())\n",
    "    \n",
    "    # 5. Find optimal ranks\n",
    "    try:\n",
    "        optimal_ranks = (\n",
    "            df_results.loc[df_results.groupby('category')['waic'].idxmin()]\n",
    "            .set_index('category')['rank']\n",
    "            .to_dict()\n",
    "        )\n",
    "        print(\"\\n✅ Optimal ranks:\")\n",
    "        for cat, rank in optimal_ranks.items():\n",
    "            print(f\"{cat}: rank {rank}\")\n",
    "            \n",
    "        return optimal_ranks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n❌ Failed to determine optimal ranks:\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Available columns:\", df_results.columns.tolist())\n",
    "        return None\n",
    "\n",
    "# Test run\n",
    "if __name__ == \"__main__\":\n",
    "    optimal_ranks = find_optimal_ranks()\n",
    "    if optimal_ranks:\n",
    "        print(\"\\nFinal result:\", optimal_ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
