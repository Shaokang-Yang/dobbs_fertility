{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21b41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"birthrate_mtgp\")\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import numpyro.distributions as dist\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "from numpyro.handlers import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435cbfc",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9644b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated data saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "path_fertility = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data with 2024.csv\"\n",
    "path_2024 = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Mother Age.csv\"\n",
    "\n",
    "# Step 1: Load both datasets\n",
    "df_fert = pd.read_csv(path_fertility)\n",
    "df_2024 = pd.read_csv(path_2024)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_2024.columns = df_2024.columns.str.strip().str.lower()\n",
    "df_2024.rename(columns={'month': 'month', 'state': 'state', 'motherage': 'age', 'births': 'births'}, inplace=True)\n",
    "\n",
    "# Step 3: Map age groups to match target columns\n",
    "def map_age_group(age):\n",
    "    if age in ['15-19', '20-24']:\n",
    "        return 'births_age1524'\n",
    "    elif age in ['25-29', '30-34']:\n",
    "        return 'births_age2534'\n",
    "    elif age in ['35-39', '40-44']:\n",
    "        return 'births_age3544'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_2024['age_group'] = df_2024['age'].apply(map_age_group)\n",
    "df_2024 = df_2024.dropna(subset=['age_group'])\n",
    "\n",
    "# Step 4: Compute bimonthly code (bmcode: 1 for Jan-Feb, ..., 6 for Nov-Dec)\n",
    "df_2024['bmcode'] = ((df_2024['month'] - 1) // 2 + 1).astype(int)\n",
    "\n",
    "# Step 5: Aggregate to state-bmcode-age_group level\n",
    "df_agg = df_2024.groupby(['state', 'bmcode', 'age_group'])['births'].sum().unstack('age_group').reset_index()\n",
    "df_agg['year'] = 2023\n",
    "\n",
    "# Step 6: Reorder and match column order with original dataset\n",
    "df_agg = df_agg[['state', 'year', 'bmcode', 'births_age1524', 'births_age2534', 'births_age3544']]\n",
    "\n",
    "# Step 7: Replace 2023 rows in original data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "df_updated = pd.concat([df_fert_no2023, df_agg], ignore_index=True)\n",
    "\n",
    "# Step 8: Save updated dataset\n",
    "output_path = path_fertility.replace(\"fertility_data with 2024.csv\", \"fertility_data_updated.csv\")\n",
    "df_updated.to_csv(output_path, index=False)\n",
    "print(\"✅ Updated data saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f71fea",
   "metadata": {},
   "source": [
    "## Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfabecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final updated file saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "fertility_updated_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated.csv\"\n",
    "marital_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Marital Status.csv\"\n",
    "\n",
    "# Step 1: Load datasets\n",
    "df_fert = pd.read_csv(fertility_updated_path)\n",
    "df_marital = pd.read_csv(marital_path)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_marital.columns = df_marital.columns.str.strip().str.lower()\n",
    "\n",
    "# Step 3: Map marital status to correct column name\n",
    "df_marital['marital_col'] = df_marital['marital_status'].map({\n",
    "    'Married': 'births_married',\n",
    "    'Unmarried': 'births_unmarried'\n",
    "})\n",
    "\n",
    "# Drop unknown statuses\n",
    "df_marital = df_marital.dropna(subset=['marital_col'])\n",
    "\n",
    "# Step 4: Calculate bmcode (1 to 6)\n",
    "df_marital['bmcode'] = ((df_marital['month'] - 1) // 2 + 1).astype(int)\n",
    "\n",
    "# Step 5: Pivot to wide format: one row per (state, bmcode), columns: births_married, births_unmarried\n",
    "df_marital_pivot = (\n",
    "    df_marital\n",
    "    .groupby(['state', 'bmcode', 'marital_col'])['births']\n",
    "    .sum()\n",
    "    .unstack('marital_col')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add year column\n",
    "df_marital_pivot['year'] = 2023\n",
    "\n",
    "# Step 6: Keep relevant columns in order\n",
    "df_marital_pivot = df_marital_pivot[['state', 'year', 'bmcode', 'births_married', 'births_unmarried']]\n",
    "\n",
    "# Step 7: Merge with previous data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "\n",
    "# First merge previous age-group replacement\n",
    "df_fert_2023 = df_fert[df_fert['year'] == 2023].drop(columns=['births_married', 'births_unmarried'], errors='ignore')\n",
    "\n",
    "# Now merge with marital data\n",
    "df_merged = pd.merge(\n",
    "    df_fert_2023,\n",
    "    df_marital_pivot,\n",
    "    on=['state', 'year', 'bmcode'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 8: Combine everything\n",
    "df_final = pd.concat([df_fert_no2023, df_merged], ignore_index=True)\n",
    "\n",
    "# Step 9: Save final dataset\n",
    "output_path = fertility_updated_path.replace(\"fertility_data_updated.csv\", \"fertility_data_updated_v2.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(\"✅ Final updated file saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff55ad",
   "metadata": {},
   "source": [
    "## Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e94406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Insurance update complete. Saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "fertility_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v2.csv\"\n",
    "insurance_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Insurance.csv\"\n",
    "\n",
    "# Step 1: Load data\n",
    "df_fert = pd.read_csv(fertility_path)\n",
    "df_ins = pd.read_csv(insurance_path)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_ins.columns = df_ins.columns.str.strip().str.lower()\n",
    "if 'insurance' not in df_ins.columns:\n",
    "    print(\"❌ Error: Could not find 'insurance' column. Found:\", df_ins.columns.tolist())\n",
    "    raise\n",
    "\n",
    "# Step 3: Classify insurance types\n",
    "df_ins['insurance_group'] = df_ins['insurance'].apply(\n",
    "    lambda x: 'births_medicaid' if x.strip().lower() == 'medicaid' else 'births_nonmedicaid'\n",
    ")\n",
    "\n",
    "# Step 4: Compute bmcode (Jan-Feb = 1, Mar-Apr = 2, ..., Nov-Dec = 6)\n",
    "df_ins['bmcode'] = ((df_ins['month'] - 1) // 2 + 1).astype(int)\n",
    "\n",
    "# Step 5: Aggregate by state-bmcode-insurance_group\n",
    "df_ins_agg = (\n",
    "    df_ins\n",
    "    .groupby(['state', 'bmcode', 'insurance_group'])['births']\n",
    "    .sum()\n",
    "    .unstack('insurance_group')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_ins_agg['year'] = 2023\n",
    "\n",
    "# Step 6: Reorder columns\n",
    "df_ins_agg = df_ins_agg[['state', 'year', 'bmcode', 'births_medicaid', 'births_nonmedicaid']]\n",
    "\n",
    "# Step 7: Separate and merge with existing 2023 data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "df_fert_2023 = df_fert[df_fert['year'] == 2023].drop(columns=['births_medicaid', 'births_nonmedicaid'], errors='ignore')\n",
    "\n",
    "# Merge on keys\n",
    "df_merged = pd.merge(df_fert_2023, df_ins_agg, on=['state', 'year', 'bmcode'], how='left')\n",
    "\n",
    "# Step 8: Combine all rows and save\n",
    "df_final = pd.concat([df_fert_no2023, df_merged], ignore_index=True)\n",
    "\n",
    "output_path = fertility_path.replace(\"fertility_data_updated_v2.csv\", \"fertility_data_updated_v3.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(\"✅ Insurance update complete. Saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bc2fd",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f498c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total births updated and saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "fertility_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v3.csv\"\n",
    "total_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Total Births.csv\"\n",
    "\n",
    "# Step 1: Load data\n",
    "df_fert = pd.read_csv(fertility_path)\n",
    "df_total = pd.read_csv(total_path)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_total.columns = df_total.columns.str.strip().str.lower()\n",
    "\n",
    "# Step 3: Compute bimonthly code\n",
    "df_total['bmcode'] = ((df_total['month'] - 1) // 2 + 1).astype(int)\n",
    "\n",
    "# Step 4: Aggregate births by state and bmcode\n",
    "df_total_agg = df_total.groupby(['state', 'bmcode'])['births'].sum().reset_index()\n",
    "df_total_agg['year'] = 2023\n",
    "df_total_agg.rename(columns={'births': 'births_total'}, inplace=True)\n",
    "\n",
    "# Step 5: Prepare the 2023 portion of fertility data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "df_fert_2023 = df_fert[df_fert['year'] == 2023].drop(columns=['births_total'], errors='ignore')\n",
    "\n",
    "# Step 6: Merge the new total births into 2023 portion\n",
    "df_fert_2023_updated = pd.merge(df_fert_2023, df_total_agg, on=['state', 'year', 'bmcode'], how='left')\n",
    "\n",
    "# Step 7: Combine and save\n",
    "df_final = pd.concat([df_fert_no2023, df_fert_2023_updated], ignore_index=True)\n",
    "\n",
    "output_path = fertility_path.replace(\"fertility_data_updated_v3.csv\", \"fertility_data_updated_v4.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(\"✅ Total births updated and saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9ad8a",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cddb3",
   "metadata": {},
   "source": [
    "## Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a082fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Population updated and saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "fertility_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v4.csv\"\n",
    "pop_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Population by Age.csv\"\n",
    "\n",
    "# Step 1: Load datasets\n",
    "df_fert = pd.read_csv(fertility_path)\n",
    "df_pop = pd.read_csv(pop_path)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_pop.columns = df_pop.columns.str.strip().str.lower()\n",
    "df_pop.rename(columns={'sate': 'state', 'age group': 'age_group'}, inplace=True)\n",
    "\n",
    "# Step 3: Map age groups to fertility categories\n",
    "def map_age_group(age):\n",
    "    if age in ['15-19', '20-24']:\n",
    "        return 'pop_age1524'\n",
    "    elif age in ['25-29', '30-34']:\n",
    "        return 'pop_age2534'\n",
    "    elif age in ['35-39', '40-44']:\n",
    "        return 'pop_age3544'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_pop['pop_group'] = df_pop['age_group'].apply(map_age_group)\n",
    "df_pop = df_pop.dropna(subset=['pop_group'])\n",
    "\n",
    "# Step 4: Aggregate to state + pop_group\n",
    "df_pop_agg = (\n",
    "    df_pop.groupby(['state', 'pop_group'])['population']\n",
    "    .sum()\n",
    "    .unstack('pop_group')\n",
    "    .reset_index()\n",
    ")\n",
    "df_pop_agg['year'] = 2023  # Population for all bmcode in 2023\n",
    "\n",
    "# Step 5: Apply this to every bmcode row in 2023 fertility data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "df_fert_2023 = df_fert[df_fert['year'] == 2023].drop(columns=['pop_age1524', 'pop_age2534', 'pop_age3544'], errors='ignore')\n",
    "\n",
    "# Merge: many-to-one on state and year\n",
    "df_fert_2023_updated = pd.merge(df_fert_2023, df_pop_agg, on=['state', 'year'], how='left')\n",
    "\n",
    "# Step 6: Combine and save\n",
    "df_final = pd.concat([df_fert_no2023, df_fert_2023_updated], ignore_index=True)\n",
    "\n",
    "output_path = fertility_path.replace(\"fertility_data_updated_v4.csv\", \"fertility_data_updated_v5.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(\"✅ Population updated and saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6af47",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d38d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pop_total updated and saved to: /Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "fertility_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v5.csv\"\n",
    "pop_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/2024 Population by Age.csv\"\n",
    "\n",
    "# Step 1: Load datasets\n",
    "df_fert = pd.read_csv(fertility_path)\n",
    "df_pop = pd.read_csv(pop_path)\n",
    "\n",
    "# Step 2: Standardize column names\n",
    "df_pop.columns = df_pop.columns.str.strip().str.lower()\n",
    "df_pop.rename(columns={'sate': 'state', 'age group': 'age_group'}, inplace=True)\n",
    "\n",
    "# Step 3: Sum all population by state (regardless of age group)\n",
    "df_total_pop = df_pop.groupby('state')['population'].sum().reset_index()\n",
    "df_total_pop['year'] = 2023\n",
    "df_total_pop.rename(columns={'population': 'pop_total'}, inplace=True)\n",
    "\n",
    "# Step 4: Prepare 2023 data\n",
    "df_fert_no2023 = df_fert[df_fert['year'] != 2023]\n",
    "df_fert_2023 = df_fert[df_fert['year'] == 2023].drop(columns=['pop_total'], errors='ignore')\n",
    "\n",
    "# Step 5: Merge total population to 2023 fertility rows\n",
    "df_fert_2023_updated = pd.merge(df_fert_2023, df_total_pop, on=['state', 'year'], how='left')\n",
    "\n",
    "# Step 6: Concatenate and save\n",
    "df_final = pd.concat([df_fert_no2023, df_fert_2023_updated], ignore_index=True)\n",
    "\n",
    "output_path = fertility_path.replace(\"fertility_data_updated_v5.csv\", \"fertility_data_updated_v6.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(\"✅ pop_total updated and saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b270f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "original_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data with 2024.csv\"\n",
    "updated_path = original_path.replace(\"fertility_data with 2024.csv\", \"fertility_data_updated_v6.csv\")\n",
    "final_output_path = original_path.replace(\"fertility_data with 2024.csv\", \"fertility_data_fully_updated.csv\")\n",
    "\n",
    "# Load original and updated datasets\n",
    "df_original = pd.read_csv(original_path)\n",
    "df_updated = pd.read_csv(updated_path)\n",
    "\n",
    "# Separate out the 2023 data in the original file\n",
    "df_original_no2023 = df_original[df_original['year'] != 2023]\n",
    "\n",
    "# Combine with the updated 2023 data\n",
    "df_updated_2023 = df_updated[df_updated['year'] == 2023]\n",
    "\n",
    "# Concatenate and save final output\n",
    "df_final = pd.concat([df_original_no2023, df_updated_2023], ignore_index=True)\n",
    "df_final.to_csv(final_output_path, index=False)\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Fully Updated Fertility Data\", dataframe=df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d675049",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_non_2023, df_merged_2023], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m df_final\u001b[38;5;241m.\u001b[39mto_csv(final_output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelective 2023 Update\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mdf_final)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Re-define paths after kernel reset\n",
    "original_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data with 2024.csv\"\n",
    "updated_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_updated_v6.csv\"\n",
    "final_output_path = \"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/dobbs_fertility/data/fertility_data_fully_updated2.csv\"\n",
    "\n",
    "# Load original and updated datasets\n",
    "df_original = pd.read_csv(original_path)\n",
    "df_updated = pd.read_csv(updated_path)\n",
    "\n",
    "# Columns to update\n",
    "columns_to_update = [\n",
    "    'births_age1524', 'births_age2534', 'births_age3544',\n",
    "    'births_married', 'births_unmarried',\n",
    "    'births_medicaid', 'births_nonmedicaid',\n",
    "    'births_total',\n",
    "    'pop_age1524', 'pop_age2534', 'pop_age3544', 'pop_total'\n",
    "]\n",
    "\n",
    "# Separate 2023 data\n",
    "df_original_2023 = df_original[df_original['year'] == 2023]\n",
    "df_non_2023 = df_original[df_original['year'] != 2023]\n",
    "df_updated_2023 = df_updated[df_updated['year'] == 2023][['state', 'year', 'bmcode'] + columns_to_update]\n",
    "\n",
    "# Merge while preserving other columns\n",
    "df_merged_2023 = pd.merge(df_original_2023, df_updated_2023, on=['state', 'year', 'bmcode'], how='left', suffixes=('', '_new'))\n",
    "\n",
    "# Replace updated columns\n",
    "for col in columns_to_update:\n",
    "    new_col = f\"{col}_new\"\n",
    "    if new_col in df_merged_2023.columns:\n",
    "        df_merged_2023[col] = df_merged_2023[new_col]\n",
    "        df_merged_2023.drop(columns=[new_col], inplace=True)\n",
    "\n",
    "# Recombine and save\n",
    "df_final = pd.concat([df_non_2023, df_merged_2023], ignore_index=True)\n",
    "df_final.to_csv(final_output_path, index=False)\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Selective 2023 Update\", dataframe=df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18aa228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ace_tools in /Users/shaokangyang/Library/Python/3.11/lib/python/site-packages (0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~andas (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e0f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ypred[1,1,1]: 9336.086\n",
      "Overall mean prediction: 12175.123730800653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the \"total\" subgroup file\n",
    "df = pd.read_csv(\"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/NB_births_total_6_through_june.csv\")\n",
    "\n",
    "# list all ypred columns\n",
    "ypred_cols = [c for c in df.columns if c.startswith(\"ypred\")]\n",
    "\n",
    "# mean prediction for state 1, quarter 1\n",
    "print(\"Mean ypred[1,1,1]:\", df[\"ypred[1,1,48]\"].mean())\n",
    "\n",
    "# overall mean across all states & times\n",
    "print(\"Overall mean prediction:\", df[ypred_cols].values.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca6828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56630.903"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ypred[1,1,48]\"].mean()+df[\"ypred[1,1,47]\"].mean()+df[\"ypred[1,1,46]\"].mean()+df[\"ypred[1,1,45]\"].mean()+df[\"ypred[1,1,44]\"].mean()+df[\"ypred[1,1,43]\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b10c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/NB_births_age_12_through_june.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747edbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shaokangyang/Library/CloudStorage/GoogleDrive-sky.ang510@gmail.com/My Drive/Code/fertility_results/2024/NB_births_age_6_through_june.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73510622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20020.541"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ypred[1,1,12]\"].mean()+df[\"ypred[1,1,11]\"].mean()+df[\"ypred[1,1,10]\"].mean()+df[\"ypred[1,1,9]\"].mean()+df[\"ypred[1,1,8]\"].mean()+df[\"ypred[1,1,7]\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1d6f1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32110.267"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ypred[2,1,12]\"].mean()+df[\"ypred[2,1,11]\"].mean()+df[\"ypred[2,1,10]\"].mean()+df[\"ypred[2,1,9]\"].mean()+df[\"ypred[2,1,8]\"].mean()+df[\"ypred[2,1,7]\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
